<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 Catching and Colliding | Perception, Action &amp; Cognition - Course Handbook</title>
  <meta name="description" content="Your textbook guide to Perception, Action and Cognition" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 Catching and Colliding | Perception, Action &amp; Cognition - Course Handbook" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="images/Title.png" />
  <meta property="og:description" content="Your textbook guide to Perception, Action and Cognition" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Catching and Colliding | Perception, Action &amp; Cognition - Course Handbook" />
  
  <meta name="twitter:description" content="Your textbook guide to Perception, Action and Cognition" />
  <meta name="twitter:image" content="images/Title.png" />

<meta name="author" content="Prof. Richard Wilkie, Dr Faisal Mushtaq, Dr Ryan Morehead and Prof. Mark Mon-Williams" />


<meta name="date" content="2020-09-23" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="how-do-we-drive.html"/>
<link rel="next" href="cognition-whats-it-all-about.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />












<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Perception, Action, Cognition</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Welcome</a></li>
<li class="chapter" data-level="2" data-path="why-do-we-percieve.html"><a href="why-do-we-percieve.html"><i class="fa fa-check"></i><b>2</b> Why do we percieve?</a><ul>
<li class="chapter" data-level="2.1" data-path="why-do-we-percieve.html"><a href="why-do-we-percieve.html#how-not-to-think-about-visual-perception"><i class="fa fa-check"></i><b>2.1</b> How NOT to think about Visual Perception</a></li>
<li class="chapter" data-level="2.2" data-path="why-do-we-percieve.html"><a href="why-do-we-percieve.html#active-perception"><i class="fa fa-check"></i><b>2.2</b> Active Perception</a></li>
<li class="chapter" data-level="2.3" data-path="why-do-we-percieve.html"><a href="why-do-we-percieve.html#why-is-perception-and-action-important"><i class="fa fa-check"></i><b>2.3</b> Why is Perception and Action Important?</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="exploring-the-world-using-our-eyes.html"><a href="exploring-the-world-using-our-eyes.html"><i class="fa fa-check"></i><b>3</b> Exploring the world using our eyes</a><ul>
<li class="chapter" data-level="3.1" data-path="exploring-the-world-using-our-eyes.html"><a href="exploring-the-world-using-our-eyes.html#why-do-we-move-our-eyes"><i class="fa fa-check"></i><b>3.1</b> Why do we move our eyes?</a></li>
<li class="chapter" data-level="3.2" data-path="exploring-the-world-using-our-eyes.html"><a href="exploring-the-world-using-our-eyes.html#different-types-of-eye-movements"><i class="fa fa-check"></i><b>3.2</b> Different Types of Eye-Movements</a><ul>
<li class="chapter" data-level="3.2.1" data-path="exploring-the-world-using-our-eyes.html"><a href="exploring-the-world-using-our-eyes.html#saccades"><i class="fa fa-check"></i><b>3.2.1</b> Saccades</a></li>
<li class="chapter" data-level="3.2.2" data-path="exploring-the-world-using-our-eyes.html"><a href="exploring-the-world-using-our-eyes.html#fixation"><i class="fa fa-check"></i><b>3.2.2</b> Fixation</a></li>
<li class="chapter" data-level="3.2.3" data-path="exploring-the-world-using-our-eyes.html"><a href="exploring-the-world-using-our-eyes.html#smooth-pursuit"><i class="fa fa-check"></i><b>3.2.3</b> Smooth Pursuit</a></li>
<li class="chapter" data-level="3.2.4" data-path="exploring-the-world-using-our-eyes.html"><a href="exploring-the-world-using-our-eyes.html#vergence"><i class="fa fa-check"></i><b>3.2.4</b> Vergence</a></li>
<li class="chapter" data-level="3.2.5" data-path="exploring-the-world-using-our-eyes.html"><a href="exploring-the-world-using-our-eyes.html#vestibulo-ocular-reflex-vor"><i class="fa fa-check"></i><b>3.2.5</b> Vestibulo-Ocular Reflex (VOR)</a></li>
<li class="chapter" data-level="3.2.6" data-path="exploring-the-world-using-our-eyes.html"><a href="exploring-the-world-using-our-eyes.html#nystagmus"><i class="fa fa-check"></i><b>3.2.6</b> Nystagmus</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="exploring-the-world-using-our-eyes.html"><a href="exploring-the-world-using-our-eyes.html#how-do-we-control-eye-movements"><i class="fa fa-check"></i><b>3.3</b> How do we control eye-movements?</a></li>
<li class="chapter" data-level="3.4" data-path="exploring-the-world-using-our-eyes.html"><a href="exploring-the-world-using-our-eyes.html#what-do-eye-movements-allow-us-to-do"><i class="fa fa-check"></i><b>3.4</b> What do eye-movements allow us to do?</a></li>
<li class="chapter" data-level="3.5" data-path="exploring-the-world-using-our-eyes.html"><a href="exploring-the-world-using-our-eyes.html#references"><i class="fa fa-check"></i><b>3.5</b> References</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="how-do-we-drive.html"><a href="how-do-we-drive.html"><i class="fa fa-check"></i><b>4</b> How do we drive?</a><ul>
<li class="chapter" data-level="4.1" data-path="how-do-we-drive.html"><a href="how-do-we-drive.html#the-core-components-of-driving"><i class="fa fa-check"></i><b>4.1</b> The Core Components of Driving</a></li>
<li class="chapter" data-level="4.2" data-path="how-do-we-drive.html"><a href="how-do-we-drive.html#what-information-is-available-for-controlling-steering"><i class="fa fa-check"></i><b>4.2</b> WHAT information is available for controlling steering?</a></li>
<li class="chapter" data-level="4.3" data-path="how-do-we-drive.html"><a href="how-do-we-drive.html#direct-vs.indirect-perception"><i class="fa fa-check"></i><b>4.3</b> Direct vs. Indirect Perception</a></li>
<li class="chapter" data-level="4.4" data-path="how-do-we-drive.html"><a href="how-do-we-drive.html#optic-flow-vs.visual-direction-information"><i class="fa fa-check"></i><b>4.4</b> Optic Flow vs. Visual Direction Information</a></li>
<li class="chapter" data-level="4.5" data-path="how-do-we-drive.html"><a href="how-do-we-drive.html#beyond-optic-flow"><i class="fa fa-check"></i><b>4.5</b> Beyond Optic Flow</a></li>
<li class="chapter" data-level="4.6" data-path="how-do-we-drive.html"><a href="how-do-we-drive.html#eye-movements-and-retinal-flow"><i class="fa fa-check"></i><b>4.6</b> Eye Movements and <em>Retinal Flow</em></a></li>
<li class="chapter" data-level="4.7" data-path="how-do-we-drive.html"><a href="how-do-we-drive.html#where-do-we-look-when-driving"><i class="fa fa-check"></i><b>4.7</b> Where do we look when driving?</a></li>
<li class="chapter" data-level="4.8" data-path="how-do-we-drive.html"><a href="how-do-we-drive.html#looking-at-the-tangent-point"><i class="fa fa-check"></i><b>4.8</b> Looking at the Tangent Point</a><ul>
<li class="chapter" data-level="4.8.1" data-path="how-do-we-drive.html"><a href="how-do-we-drive.html#formalising-the-relationship-between-fixating-the-tangent-point-and-steering"><i class="fa fa-check"></i><b>4.8.1</b> Formalising the relationship between fixating the Tangent Point AND steering</a></li>
</ul></li>
<li class="chapter" data-level="4.9" data-path="how-do-we-drive.html"><a href="how-do-we-drive.html#problems-for-the-tangent-point"><i class="fa fa-check"></i><b>4.9</b> Problems for the Tangent Point</a></li>
<li class="chapter" data-level="4.10" data-path="how-do-we-drive.html"><a href="how-do-we-drive.html#how-essential-is-the-tangent-point"><i class="fa fa-check"></i><b>4.10</b> How Essential is the Tangent Point?</a></li>
<li class="chapter" data-level="4.11" data-path="how-do-we-drive.html"><a href="how-do-we-drive.html#if-steering-is-shifted-what-happens-to-gaze"><i class="fa fa-check"></i><b>4.11</b> If Steering is Shifted, What Happens to Gaze?</a></li>
<li class="chapter" data-level="4.12" data-path="how-do-we-drive.html"><a href="how-do-we-drive.html#if-gaze-is-shifted-what-happens-to-steering"><i class="fa fa-check"></i><b>4.12</b> If Gaze is Shifted, What Happens to Steering?</a></li>
<li class="chapter" data-level="4.13" data-path="how-do-we-drive.html"><a href="how-do-we-drive.html#taking-the-racing-line"><i class="fa fa-check"></i><b>4.13</b> Taking the Racing Line</a></li>
<li class="chapter" data-level="4.14" data-path="exploring-the-world-using-our-eyes.html"><a href="exploring-the-world-using-our-eyes.html#references"><i class="fa fa-check"></i><b>4.14</b> References</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="catching-and-colliding.html"><a href="catching-and-colliding.html"><i class="fa fa-check"></i><b>5</b> Catching and Colliding</a><ul>
<li class="chapter" data-level="5.1" data-path="catching-and-colliding.html"><a href="catching-and-colliding.html#judging-time-to-contact-ttc"><i class="fa fa-check"></i><b>5.1</b> Judging Time to Contact (TTC)</a></li>
<li class="chapter" data-level="5.2" data-path="catching-and-colliding.html"><a href="catching-and-colliding.html#evidence-for-the-use-of-tau-in-the-real-world"><i class="fa fa-check"></i><b>5.2</b> Evidence for the Use of Tau in the Real-World</a></li>
<li class="chapter" data-level="5.3" data-path="catching-and-colliding.html"><a href="catching-and-colliding.html#is-tau-really-the-only-control-variable-for-interceptive-timing"><i class="fa fa-check"></i><b>5.3</b> Is Tau Really the Only Control Variable for Interceptive Timing?</a></li>
<li class="chapter" data-level="5.4" data-path="catching-and-colliding.html"><a href="catching-and-colliding.html#what-other-information-might-we-use-to-gauge-ttc"><i class="fa fa-check"></i><b>5.4</b> What Other Information Might We Use to Gauge TTC?</a></li>
<li class="chapter" data-level="5.5" data-path="catching-and-colliding.html"><a href="catching-and-colliding.html#virtual-reality-vr---to-go-in-a-blue-box"><i class="fa fa-check"></i><b>5.5</b> Virtual Reality (VR) - TO GO IN A BLUE BOX</a></li>
<li class="chapter" data-level="5.6" data-path="catching-and-colliding.html"><a href="catching-and-colliding.html#does-it-matter-where-you-look"><i class="fa fa-check"></i><b>5.6</b> Does it Matter Where You Look?</a></li>
<li class="chapter" data-level="5.7" data-path="exploring-the-world-using-our-eyes.html"><a href="exploring-the-world-using-our-eyes.html#references"><i class="fa fa-check"></i><b>5.7</b> References</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="cognition-whats-it-all-about.html"><a href="cognition-whats-it-all-about.html"><i class="fa fa-check"></i><b>6</b> Cognition - What’s it all about?</a><ul>
<li class="chapter" data-level="6.1" data-path="cognition-whats-it-all-about.html"><a href="cognition-whats-it-all-about.html#so-what-is-cognitive-psychology"><i class="fa fa-check"></i><b>6.1</b> So, What is Cognitive Psychology?</a></li>
<li class="chapter" data-level="6.2" data-path="cognition-whats-it-all-about.html"><a href="cognition-whats-it-all-about.html#so-what-is-information"><i class="fa fa-check"></i><b>6.2</b> So, What is Information?</a></li>
<li class="chapter" data-level="6.3" data-path="cognition-whats-it-all-about.html"><a href="cognition-whats-it-all-about.html#cognition-action-interactions"><i class="fa fa-check"></i><b>6.3</b> Cognition Action Interactions</a></li>
<li class="chapter" data-level="6.4" data-path="cognition-whats-it-all-about.html"><a href="cognition-whats-it-all-about.html#so-what-is-perception"><i class="fa fa-check"></i><b>6.4</b> So, What is Perception?</a></li>
<li class="chapter" data-level="6.5" data-path="cognition-whats-it-all-about.html"><a href="cognition-whats-it-all-about.html#vision-is-a-robust-system"><i class="fa fa-check"></i><b>6.5</b> Vision is a Robust System</a></li>
<li class="chapter" data-level="6.6" data-path="cognition-whats-it-all-about.html"><a href="cognition-whats-it-all-about.html#visual-information"><i class="fa fa-check"></i><b>6.6</b> Visual information</a></li>
<li class="chapter" data-level="6.7" data-path="exploring-the-world-using-our-eyes.html"><a href="exploring-the-world-using-our-eyes.html#references"><i class="fa fa-check"></i><b>6.7</b> References</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="vision-what-is-it-good-for.html"><a href="vision-what-is-it-good-for.html"><i class="fa fa-check"></i><b>7</b> Vision - What is it good for?</a><ul>
<li class="chapter" data-level="7.1" data-path="vision-what-is-it-good-for.html"><a href="vision-what-is-it-good-for.html#processing-information"><i class="fa fa-check"></i><b>7.1</b> Processing information</a></li>
<li class="chapter" data-level="7.2" data-path="vision-what-is-it-good-for.html"><a href="vision-what-is-it-good-for.html#a-fundamental-problem"><i class="fa fa-check"></i><b>7.2</b> A fundamental problem</a></li>
<li class="chapter" data-level="7.3" data-path="vision-what-is-it-good-for.html"><a href="vision-what-is-it-good-for.html#the-nature-of-visual-processing"><i class="fa fa-check"></i><b>7.3</b> The nature of visual processing</a></li>
<li class="chapter" data-level="7.4" data-path="vision-what-is-it-good-for.html"><a href="vision-what-is-it-good-for.html#two-visual-streams"><i class="fa fa-check"></i><b>7.4</b> Two visual streams</a></li>
<li class="chapter" data-level="7.5" data-path="vision-what-is-it-good-for.html"><a href="vision-what-is-it-good-for.html#object-recognition"><i class="fa fa-check"></i><b>7.5</b> Object recognition</a></li>
<li class="chapter" data-level="7.6" data-path="vision-what-is-it-good-for.html"><a href="vision-what-is-it-good-for.html#object-recognition-physiology"><i class="fa fa-check"></i><b>7.6</b> Object recognition physiology</a></li>
<li class="chapter" data-level="7.7" data-path="vision-what-is-it-good-for.html"><a href="vision-what-is-it-good-for.html#object-recognition-neuropsychology"><i class="fa fa-check"></i><b>7.7</b> Object recognition neuropsychology</a></li>
<li class="chapter" data-level="7.8" data-path="vision-what-is-it-good-for.html"><a href="vision-what-is-it-good-for.html#categorising-faces"><i class="fa fa-check"></i><b>7.8</b> Categorising faces</a></li>
<li class="chapter" data-level="7.9" data-path="exploring-the-world-using-our-eyes.html"><a href="exploring-the-world-using-our-eyes.html#references"><i class="fa fa-check"></i><b>7.9</b> References</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="gauging-the-third-dimension.html"><a href="gauging-the-third-dimension.html"><i class="fa fa-check"></i><b>8</b> Gauging the third dimension</a><ul>
<li class="chapter" data-level="8.1" data-path="gauging-the-third-dimension.html"><a href="gauging-the-third-dimension.html#distance-and-layout-perception"><i class="fa fa-check"></i><b>8.1</b> Distance and layout perception</a></li>
<li class="chapter" data-level="8.2" data-path="gauging-the-third-dimension.html"><a href="gauging-the-third-dimension.html#cue-combination"><i class="fa fa-check"></i><b>8.2</b> Cue combination</a></li>
<li class="chapter" data-level="8.3" data-path="gauging-the-third-dimension.html"><a href="gauging-the-third-dimension.html#distance-and-layout-information"><i class="fa fa-check"></i><b>8.3</b> Distance and layout information</a></li>
<li class="chapter" data-level="8.4" data-path="gauging-the-third-dimension.html"><a href="gauging-the-third-dimension.html#body-scaled-distance-cues"><i class="fa fa-check"></i><b>8.4</b> Body-scaled distance cues</a><ul>
<li class="chapter" data-level="8.4.1" data-path="gauging-the-third-dimension.html"><a href="gauging-the-third-dimension.html#accommodation"><i class="fa fa-check"></i><b>8.4.1</b> Accommodation</a></li>
<li class="chapter" data-level="8.4.2" data-path="exploring-the-world-using-our-eyes.html"><a href="exploring-the-world-using-our-eyes.html#vergence"><i class="fa fa-check"></i><b>8.4.2</b> Vergence</a></li>
<li class="chapter" data-level="8.4.3" data-path="gauging-the-third-dimension.html"><a href="gauging-the-third-dimension.html#vertical-image-disparities"><i class="fa fa-check"></i><b>8.4.3</b> Vertical image disparities</a></li>
<li class="chapter" data-level="8.4.4" data-path="gauging-the-third-dimension.html"><a href="gauging-the-third-dimension.html#vertical-gaze-angle"><i class="fa fa-check"></i><b>8.4.4</b> Vertical gaze angle</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="gauging-the-third-dimension.html"><a href="gauging-the-third-dimension.html#relative-information"><i class="fa fa-check"></i><b>8.5</b> Relative information</a><ul>
<li class="chapter" data-level="8.5.1" data-path="gauging-the-third-dimension.html"><a href="gauging-the-third-dimension.html#horizontal-retinal-image-disparities"><i class="fa fa-check"></i><b>8.5.1</b> Horizontal retinal image disparities</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="gauging-the-third-dimension.html"><a href="gauging-the-third-dimension.html#ordinal-information"><i class="fa fa-check"></i><b>8.6</b> Ordinal information</a></li>
<li class="chapter" data-level="8.7" data-path="gauging-the-third-dimension.html"><a href="gauging-the-third-dimension.html#how-is-vergence-used"><i class="fa fa-check"></i><b>8.7</b> How is vergence used?</a></li>
<li class="chapter" data-level="8.8" data-path="gauging-the-third-dimension.html"><a href="gauging-the-third-dimension.html#distance-perception-in-visual-form-agnosia"><i class="fa fa-check"></i><b>8.8</b> Distance perception in visual form agnosia</a></li>
<li class="chapter" data-level="8.9" data-path="exploring-the-world-using-our-eyes.html"><a href="exploring-the-world-using-our-eyes.html#references"><i class="fa fa-check"></i><b>8.9</b> References</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="using-vision-to-control-the-hand.html"><a href="using-vision-to-control-the-hand.html"><i class="fa fa-check"></i><b>9</b> Using vision to control the hand</a><ul>
<li class="chapter" data-level="9.1" data-path="using-vision-to-control-the-hand.html"><a href="using-vision-to-control-the-hand.html#the-pre-contact-phase"><i class="fa fa-check"></i><b>9.1</b> The pre-contact phase</a></li>
<li class="chapter" data-level="9.2" data-path="using-vision-to-control-the-hand.html"><a href="using-vision-to-control-the-hand.html#the-spatial-path-of-the-transport-component"><i class="fa fa-check"></i><b>9.2</b> The spatial path of the transport component</a></li>
<li class="chapter" data-level="9.3" data-path="using-vision-to-control-the-hand.html"><a href="using-vision-to-control-the-hand.html#the-spatial-pattern-of-the-grasp-component"><i class="fa fa-check"></i><b>9.3</b> The spatial pattern of the grasp component</a></li>
<li class="chapter" data-level="9.4" data-path="using-vision-to-control-the-hand.html"><a href="using-vision-to-control-the-hand.html#the-timing-of-the-transport-component"><i class="fa fa-check"></i><b>9.4</b> The timing of the transport component</a></li>
<li class="chapter" data-level="9.5" data-path="using-vision-to-control-the-hand.html"><a href="using-vision-to-control-the-hand.html#what-does-mt-a-b-log2a-c-log2w-actually-mean"><i class="fa fa-check"></i><b>9.5</b> What does MT= a + b log2A + c log2W actually mean?</a></li>
<li class="chapter" data-level="9.6" data-path="using-vision-to-control-the-hand.html"><a href="using-vision-to-control-the-hand.html#the-contact-phase"><i class="fa fa-check"></i><b>9.6</b> The contact phase</a></li>
<li class="chapter" data-level="9.7" data-path="using-vision-to-control-the-hand.html"><a href="using-vision-to-control-the-hand.html#programming-fingertip-forces"><i class="fa fa-check"></i><b>9.7</b> Programming fingertip forces</a></li>
<li class="chapter" data-level="9.8" data-path="using-vision-to-control-the-hand.html"><a href="using-vision-to-control-the-hand.html#internal-models"><i class="fa fa-check"></i><b>9.8</b> Internal models</a></li>
<li class="chapter" data-level="9.9" data-path="exploring-the-world-using-our-eyes.html"><a href="exploring-the-world-using-our-eyes.html#references"><i class="fa fa-check"></i><b>9.9</b> References</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="mailto:f.mushtaq@leeds.ac.uk" target="blank">Spot an error? Email here</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Perception, Action &amp; Cognition - Course Handbook</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="catching-and-colliding" class="section level1">
<h1><span class="header-section-number">Chapter 5</span> Catching and Colliding</h1>
<p>In my <strong>last lecture</strong> I talked about the problem of controlling steering using visual information when approaching a distant object (whilst keeping yourself safely between the road edges).</p>
<p>Catching (more generally referred to as the control of interception) is in some ways the inverse of steering, since rather than you moving towards the object, the distant object approaches you.</p>
<p>In this scenario what your system wants to know is “when will the object arrive” – which is usually referred to as the “time-to-contact” (TTC).
Once you know TTC you should be able to adjust your arm/hand movements in order to close your hand at the correct time and carry out a successful catch.
Hopefully you are thinking to yourself:</p>
<p>“Hang on, when I am catching I often need to run to get myself in the correct location first before reaching out and getting my hand in the right location”.
In fact the same TTC information should be useful when running (or driving) to let you control your rate of acceleration/deceleration so you stop in the correct place.</p>
<p>Coordinating locomotion with interception is a more complex scenario that goes beyond the scope of this lecture (though it is an active area of research so feel free to look up the latest literature on it).</p>
<div id="judging-time-to-contact-ttc" class="section level2">
<h2><span class="header-section-number">5.1</span> Judging Time to Contact (TTC)</h2>
<p>Humans are able to catch objects and avoid colliding with objects so it seems we are able to gauge TTC.
We know that the retina supplies our brain with useful information, and so it is useful to consider what retinal information is available that would allow us to gauge TTC.
If we start with the simplest case of a symmetrical ball coming towards your eye, what information is available to tell you when it will arrive? Physics tells us that TTC is based upon the real-world velocity (v) and distance (z) of the ball (v = z/time, so TTC = z/v).
It is unlikely that our system carries out this particular calculation since it doesn’t have direct access to velocity information and distance information is often distorted or imprecise (see <strong>Lecture 8</strong>).
Luckily the optical properties of the ball (i.e. the information at the retina) can be sufficient to determine TTC without recourse to calculating velocity and distance.
Sir Fred Hoyle first pointed out that time to contact information is available from the rate of expansion of an approaching object.
The figure to the right shows a slice through a yellow ball of physical size (S) approaching the eye at velocity (vz).
The retinal size (aka ‘optical size’) is linked to the distance since when closer it looks bigger (in technical terms it ‘subtends a larger angle’) on the retina.
As the ball gets closer (moves in the world from Z(1) to Z(2)) the retinal image size increases from r(1) to r(2) - the retinal velocity (vr) is therefore linked to the real world velocity (vz).
The ratio of retinal size to retinal velocity (r/Vr) was championed by David Lee<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> as a variable used for interceptive timing in the animal kingdom and he dubbed it the ‘Tau ratio’ (a ratio is the relationship between two numbers when divided, namely r/Vr).
Tau (arbitrarily named after the Greek letter <span class="math inline">\(\tau\)</span>) was greeted enthusiastically by a number of ‘ecological’ (Gibsonian) psychologists because it seemed to be a good example of invariant information that could be ‘directly’ detected from the optic array (remember that optic flow has been embraced in a similar way for the control of steering).
It is important to note that although tau can, in principle, provide time to contact information, it is a different issue as to whether animals actually use this source of information.
Another thing to clarify is that even though the relationship described above uses mathematics, this does not mean that you have to explicitly carry out these calculations in your head.
If we are able to use Tau to carry out actions then there should be a set of neurons that examine information from the retina and the relationship between retinal size and velocity of approaching objects to support rapid actions.
It would be very difficult for a human to successfully interact with the world based on cognitive conscious calculations because they would be impossibly slow.</p>
<div class="figure">
<img src="images/L5_F1.png" alt="Tau and TTC." />
<p class="caption">Tau and TTC.</p>
</div>
<p>The papers in this area of research use a variety of terminology so perhaps it’s time for a few formal definitions:</p>
<ul>
<li><p>Retinal size – the size of an object on the retina. This is usually measured in angular units (e.g. degrees) and can often be denoted by the Greek character theta (<span class="math inline">\(\theta\)</span>).</p></li>
<li><p>Optic expansion – the increase in retinal size of an object (retinal velocity, or Vr), also known as “<strong>looming</strong>”. Sometimes denoted at d<span class="math inline">\(\theta\)</span>/dt : meaning change in retinal size divided by the change in time (d is often used to indicate ‘change’ – delta (<span class="math inline">\(\Delta\)</span>) can also represent this too).</p></li>
<li><p>Tau ratio - the retinal size (r) divided by the retinal velocity of optic expansion (Vr)</p></li>
</ul>
<div class="figure">
<img src="images/L5_F2.png" alt="It is hypothesised that sea birds may use tau to judge TTC." width="320" />
<p class="caption">It is hypothesised that sea birds may use tau to judge TTC.</p>
</div>
</div>
<div id="evidence-for-the-use-of-tau-in-the-real-world" class="section level2">
<h2><span class="header-section-number">5.2</span> Evidence for the Use of Tau in the Real-World</h2>
<p>Lee &amp; Reddish (1981) provided evidence that gannets use tau by showing that they folded their wings at a particular TTC with the water.
Following this (very) influential study, a number of researchers sought further evidence for the use of tau by animals and humans (Yes, I know that science is supposed to test hypotheses rather than seek evidence in support of them).
Over the years a wide number of studies purported to find evidence for the use of tau in humans (e.g. Ski-jumpers taking off: Lee, Lishman &amp; Thompson, 1982) and animals.
Gradually people came to believe that tau and TTC information were one and the same thing.
Unfortunately, all these studies were observational and so at best showed behaviour that was consistent with the use of tau, rather than testing tau directly (e.g. by manipulating the available information in a standard experimental psychology manner).</p>
</div>
<div id="is-tau-really-the-only-control-variable-for-interceptive-timing" class="section level2">
<h2><span class="header-section-number">5.3</span> Is Tau Really the Only Control Variable for Interceptive Timing?</h2>
<p>It was James Tresilian (1990) who first began to raise doubts about the ability of tau to explain interceptive timing behaviour in humans.
He pointed out a number of problems with tau: i) it assumes a constant target velocity (it doesn’t take accelerations into account), ii) the target must be heading directly towards the eye, and iii) if it is non-spherical, it cannot be rotating.
He showed at a theoretical level that tau alone couldn’t possibly account for the accurate time to contact behaviour made by humans across a wide range of tasks.
Tresilian (1990) did, however, propose a general solution to the problems raised by the original formulation of tau and suggested that tau could contribute a first order approximation to the actual time to arrival for use in fast interceptive actions.</p>
<p>Despite Tresilian’s theoretical musings, there was still a large body of scientific literature that supposedly showed humans and animals using tau as the sole timing variable.
John Wann (1996) reviewed all of these studies, however, and showed that each of them had fundamental flaws, with the data not necessarily supporting the conclusions.
Most notably he identified that the gannets were actually diving from heights between 31cm and 1m high (rather than large graceful dives, they were really bobbing their heads whilst picking up fish being thrown from the back of a fishing boat).</p>
</div>
<div id="what-other-information-might-we-use-to-gauge-ttc" class="section level2">
<h2><span class="header-section-number">5.4</span> What Other Information Might We Use to Gauge TTC?</h2>
<p>If humans do not use tau as the sole timing variable, what other information might they be using?
One possibility is that when observers have two eyes open they use binocular information (see <strong>Lecture 8</strong>).
We can hypothesise that there are two sources of information used by humans for gauging time to contact. The first is binocular (ratio of the rate of change of vergence OR horizontal disparity— we will assume the two are equivalent) and the second is the ‘monocular’ cue of looming.
The binocular cue can provide time to contact information in the same way as the looming cue—
i.e. without recourse to knowing the distance or the velocity of the ball.
It should be noted that binocular information is likely to be most effective for small balls and looming most effective for larger balls.
Notably, catching a ball will often involve running, moving the head etc., so that binocular information will vary in its reliability.</p>
<div class="figure">
<img src="images/L5_F3.png" alt="VR has been used to manipulate looming." width="320" />
<p class="caption">VR has been used to manipulate looming.</p>
</div>
<p>Rushton &amp; Wann (1999) tested whether these sources of information are used by perturbing the looming and/or the binocular information inside a ‘virtual reality’ display (see box below).
Rushton &amp; Wann found evidence that the nervous system uses both forms of information—
i.e. perturbing either of these cues caused timing errors.
Rushton &amp; Wann were able to model their data using a simple scheme that they called <strong>the ‘dipole’ model</strong> (what a pretentious title!).
The dipole model copes with ‘cue drop out’ (e.g. losing a binocular view of the ball) by implicitly switching to the remaining cue and switching back to dual weighting if both cues become available.
If a conflict arises between the looming and the binocular information then the model simply increases the weight of the most immediate cue (that is, the one which specifies the shortest time to contact).
This makes good sense because it is better to duck too early in the real world than too late!</p>
</div>
<div id="virtual-reality-vr---to-go-in-a-blue-box" class="section level2">
<h2><span class="header-section-number">5.5</span> Virtual Reality (VR) - TO GO IN A BLUE BOX</h2>
<p>The information sources in the real-world tend to be consistent:
as a ball approaches our eyes the retinal size increases and the binocular disparities increase.
While it is possible to devise real-world experiments that alter this relationship (e.g. having a deflating ball) it is often hard to do this in a controlled and systematic way.
Virtual reality displays use the power of modern computers to generate moving images and present them to the eye in order to simulate the real-world properties of objects and surfaces within the world.
In a head mounted display (like that shown in the Figure), the images are presented to the eyes through small screens placed in front of each eye.
Most importantly such techniques allow us to change the relationship between different variables (e.g. retinal size and binocular disparity) so they are no longer consistent.
A VR headset generally displays two slightly different images to your eyes (to recreate normal binocular disparity) but can allow the disparities to be increased or reduced completely independent of optic size.
Similarly retinal size can be altered without binocular disparity information being affected.
We can use such manipulations to test if a source of information is being used to control catching, and if so, how much the system relies on each source (the weighting).</p>
<p>The additional power of VR is that the experiments can alter the visual information based on the behaviour of the participant.
For example in my steering experiments, turning the wheel alters the visual information projected to the eye, and we could readily change the visual information in the display based on other behaviours (e.g. eye-movements).
Such interactive displays allow us to investigate complex skilled behaviours that rely upon feedback in order to be successful.</p>
</div>
<div id="does-it-matter-where-you-look" class="section level2">
<h2><span class="header-section-number">5.6</span> Does it Matter Where You Look?</h2>
<p>The short answer is: yes.
If you don’t look at the approaching object then you won’t have a good vergence signal which might make it harder to gauge TTC.
In order to examine this question it is useful to consider where we actually look when an object is approaching.
Mike Land stepped up with another real-world study, this time looking at cricketers batting (Land &amp; McLeod, 2000).
Batting in cricket is a slightly different case from catching since the ball tends to bounce off the ground rather than expand towards your head (unless you are a really bad bowler).
In their observations batters tracked the ball for ~200ms until they had enough information to make a <strong>predictive</strong> saccade to where they thought the ball would bounce – they fixated that point on the ground until the ball bounced at which point they tracked the ball for the rest of the trajectory.
It seems that image expansion (Tau) is unlikely to be used when they do not look at the ball, but in the later stages (after the bounce) Tau and binocular disparity might be useful sources of information for gauging TTC.</p>
<div class="figure">
<img src="images/L5_F4.png" alt="Vergence is used ot imporove TTC judgements." />
<p class="caption">Vergence is used ot imporove TTC judgements.</p>
</div>
<p>Tresilian has argued that there is no single strategy for all timing judgements and suggested that the nervous system learns to use whatever information is available in any way it can in order to achieve satisfactory performance.
The paper by Land &amp; McLeod (2000) would seem to support that since there are a number of unique informational variables peculiar to batting at cricket that would not be useful in other situations even in a game that has many similarities (e.g. baseball).
Lopez-Moliner, Field and Wann (2007) have shown that an additional source of information that can be useful to you when catching is the known size of the ball that is coming towards you (e.g. knowing it is a cricket ball rather than a football).
This may seem obvious but it goes even further against the Gibsonian view of perception &amp; action.
Not only does it seem that there is not one single informational invariant for interceptive timing, but having prior stored information (representation) about real world objects changes how you perceive and act.
Having a stored estimate about the properties of world objects seems to be generally useful (this will come u again in <strong>Lecture 9</strong>) but it is still an open question the form that these estimates take and how transient they are.
For instance it is unlikely that we have the capacity to store size and weight information about every object we have ever interacted with.
In his lecture Jeff will be following on from this theme and discussing the capacity limits of short-term memory storage of visual information.</p>
</div>
<div id="references" class="section level2">
<h2><span class="header-section-number">5.7</span> References</h2>
<p>Gibson, J. J. (1958). <em>Visually controlled locomotion and visual orientation in animals</em>. British Journal Psychology, 49, 182-194.</p>
<p>Land, M. F. &amp; McLeod, P. (2000). <em>From eye movements to actions: how batsmen hit the ball</em>. Nature Neuroscience, 3(12), 1340-1345.</p>
<p>Lee, D. N. (1976). <em>A theory of visual control of braking based on information about time-to-collision</em>. Perception, 5, 437-459.</p>
<p>López-Moliner, J., Field, D. T., &amp; Wann, J. P. (2007). <em>Interceptive timing: Prior knowledge matters</em>. Journal of Vision, 7(13):11, 1-8.</p>
<p>– Lee, D. N. &amp; Reddish P. E. (1981). <em>Plummeting Gannets: a paradigm of ecological optics</em>. Nature, 293.</p>
<p>– Rushton, S. K. &amp; Wann, J. P. (1999). <em>Weighted combination of size and disparity: a computational model for timing a ball catch</em>. Nature. 2(2), 186-190.</p>
<p>Tresilian, J. (1990). <em>Perceptual information for the timing of interceptive action</em>. Perception, 19(2), 223-239</p>
<p>– Wann, J. P. (1996). <em>Anticipating arrival: Is the tau margin a specious theory?</em> Journal of Experimental Psychology: Human Perception and Performance, 22, 1031-1048.</p>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>Yes – this is the same Lee as in Land &amp; Lee (1994) Where you look when you drive. Gets around doesn’t he?<a href="catching-and-colliding.html#fnref1" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="how-do-we-drive.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="cognition-whats-it-all-about.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/04-catching-and-colliding.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
